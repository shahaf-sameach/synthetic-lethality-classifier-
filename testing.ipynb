{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from goatools.base import get_godag\n",
    "from goatools.anno.gaf_reader import GafReader\n",
    "from goatools.gosubdag.gosubdag import GoSubDag\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "#Get the GO terms\n",
    "godag = get_godag(\"go-basic.obo\", optional_attrs='relationship')\n",
    "#Get the GO Annotation File\n",
    "gogaf = GafReader(\"goa_yeast.gaf\")\n",
    "#Build pairs and sl columns in gene2sl\n",
    "genes     = pd.read_csv('gsets_1', header=None, names=[\"genes\"])\n",
    "sl_lables = pd.read_csv('sl_1', header=None, names=[\"sl\"])\n",
    "gene2sl   = pd.concat([genes, sl_lables], axis=1)\n",
    "#gene2sl   = gene2sl.set_index('genes')\n",
    "#Now get a gene to GO id dict.\n",
    "gene2goid = defaultdict(set)\n",
    "for assoc in gogaf.associations:\n",
    "    for syn in assoc.DB_Synonym:\n",
    "        gene2goid[syn].add(assoc.GO_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from scipy.stats.stats import pearsonr\n",
    "np.random.seed(0)  # seed for reproducibility\n",
    "\n",
    "x = np.random.randint(10, size=6000)  # One-dimensional array\n",
    "y = np.random.randint(10, size=6000)  # One-dimensional array\n",
    "print(pearsonr(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'tcga_data.csv' does not exist: b'tcga_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'tcga_data.csv' does not exist: b'tcga_data.csv'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "# mmc = pd.read_excel(\"mmc5.xlsx\")\n",
    "# mmc.head(25)\n",
    "tcga = pd.read_csv(\"tcga_data.csv\", sep=\"\\t\")\n",
    "tcga.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horlbeck_data = pd.read_excel(\"mmc5.xlsx\", sheet_name=1, header=None, skiprows=4, usecols=[0,1,6])\n",
    "horlbeck_data.set_index([0,1]).sort_index().dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horlbeck_data[6].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horlbeck_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(gogaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(godag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = godag.get('GO:0010468')\n",
    "term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = term.parents\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#%%prun\n",
    "\n",
    "#Now build the hierarchy, meaning each node is represented by the no. of all its descendants\n",
    "genes2terms = pd.DataFrame()\n",
    "gene2terms = {}\n",
    "list_genes2terms = []\n",
    "for index, row in gene2sl.iterrows():\n",
    "    for gene in row['genes'].split(\"$\"):\n",
    "        #No such gene, build it\n",
    "        if gene not in gene2terms:\n",
    "            gene2terms[gene] = {}\n",
    "            genebiogoid = []\n",
    "            go_ids = gene2goid.get(gene)\n",
    "            if go_ids is None:\n",
    "                print(\"Could not find the gene {} in GAF\".format(gene))               \n",
    "            else:\n",
    "                for go_id in go_ids:\n",
    "                    term = godag.get(go_id)\n",
    "                    if term.namespace == 'biological_process':                     \n",
    "                        #Get the leaf GO term\n",
    "                        genebiogoid.append(go_id)  \n",
    "                        #Mark the visitation of that leaf\n",
    "                        if go_id not in gene2terms[gene]:\n",
    "                            gene2terms[gene][go_id] = 1\n",
    "                        else:\n",
    "                            gene2terms[gene][go_id] += 1\n",
    "            # Create a subset of the GO DAG which contains:\n",
    "            # The common GO terms that are 'is_a' for the gene, by setting relationships=False\n",
    "            gosubdag = GoSubDag(genebiogoid, godag, relationships=False, prt=False) \n",
    "            ancestors = defaultdict(set)\n",
    "            if go_id in gosubdag.rcntobj.go2parents:\n",
    "                for p_go in gosubdag.rcntobj.go2parents[go_id]:\n",
    "                    dict_anc = gosubdag.go2nt[p_go]._asdict()\n",
    "                    ancestors[dict_anc['depth']].add(dict_anc['GO'])                            \n",
    "            #Sum up all the ancestors values (the root is marked as depth 0)\n",
    "            count_genes = 1  \n",
    "            for level in range(len(ancestors) - 1, -1, -1):\n",
    "                for GO in ancestors[level]:\n",
    "                    if GO not in gene2terms[gene]:\n",
    "                        gene2terms[gene][GO] = count_genes\n",
    "                    else:\n",
    "                        gene2terms[gene][GO] += count_genes                                \n",
    "                count_genes += len(ancestors[level])                          \n",
    "    #Build the combination of the 2 genes\n",
    "    g1, g2 = row['genes'].split(\"$\")\n",
    "    gene1 = gene2terms[g1]\n",
    "    gene2 = gene2terms[g2]         \n",
    "    genesdict = {key: gene1.get(key, 0) + gene2.get(key, 0)\n",
    "                 for key in set(gene1) | set(gene2)}\n",
    "    genesdict['genes'] = row['genes']\n",
    "    genesdict['sl'] = row['sl']\n",
    "    list_genes2terms.append(genesdict)    \n",
    "    if index == 100:\n",
    "        break\n",
    "#Add the final data and clean NaN\n",
    "genes2terms = genes2terms.append(list_genes2terms, ignore_index=True)\n",
    "genes2terms = genes2terms.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(list_genes2terms, fp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"list_genes2terms.txt\", \"rb\") as fp:   # Unpickling\n",
    "     b = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes2terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_g2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes2terms = pd.DataFrame()\n",
    "gene2terms = {}\n",
    "for index, row in gene2sl.iterrows():\n",
    "    genebiogoid = []\n",
    "    for gene in row['genes'].split(\"$\"):\n",
    "        #No such gene, build it\n",
    "        if gene not in gene2terms:\n",
    "            go_ids = gene2goid.get(gene)\n",
    "            if go_ids is None:\n",
    "                print(\"Could not find the gene {} in GAF\".format(gene))               \n",
    "            else:\n",
    "                for go_id in go_ids:\n",
    "                    term = godag.get(go_id)\n",
    "                    if term.namespace == 'biological_process':\n",
    "                        #Get the leaf GO term\n",
    "                        genebiogoid.append(go_id)                        \n",
    "            #Build the combination of the 2 genes\n",
    "            # Create a subset of the GO DAG which contains:\n",
    "            # The selected GO term and the 'is_a' GO terms above it, by setting relationships=False\n",
    "            gene2terms[gene] = {}\n",
    "            gosubdag = GoSubDag(genebiogoid, godag, relationships=False, prt=False) \n",
    "            ancestors = defaultdict(set)\n",
    "            for p_genegoid in genebiogoid:\n",
    "                count_genes = 1 \n",
    "                if p_genegoid not in genesdict:\n",
    "                    gene2terms[p_genegoid] = count_genes\n",
    "                else:\n",
    "                    gene2terms[p_genegoid] += count_genes \n",
    "                if p_genegoid in gosubdag.rcntobj.go2parents:\n",
    "                    for p_go in gosubdag.rcntobj.go2parents[p_genegoid]:\n",
    "                            dict_anc = gosubdag.go2nt[p_go]._asdict()\n",
    "                            ancestors[dict_anc['depth']].add(dict_anc['GO'])\n",
    "                #Sum up all the ancestors values\n",
    "            for level in range(len(ancestors) - 1, -1, -1):\n",
    "                for GO in ancestors[level]:\n",
    "                    if GO not in genesdict:\n",
    "                        gene2terms[GO] = count_genes\n",
    "                    else:\n",
    "                        gene2terms[GO] += count_genes                                \n",
    "                    count_genes += len(ancestors[level])  \n",
    "    g1, g2 = row['genes'].split(\"$\")\n",
    "    gene1 = gene2terms[g1]\n",
    "    gene2 = gene2terms[g2]         \n",
    "    genesdict = {key: gene1.get(key, 0) + gene2.get(key, 0)\n",
    "                 for key in set(gene1) | set(gene2)}\n",
    "    genesdict['genes'] = row['genes']\n",
    "    genesdict['sl'] = row['sl']\n",
    "    #Add the final line and clean NaN\n",
    "    genes2terms = genes2terms.append(genesdict, ignore_index=True)\n",
    "    genes2terms = genes2terms.fillna(0)\n",
    "    break\n",
    "    print(index)\n",
    "    if index == 100: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# #############################################################################\n",
    "# Data IO and generation\n",
    "\n",
    "# Import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X, y = X[y != 2], y[y != 2]\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# Add noisy features\n",
    "random_state = np.random.RandomState(0)\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# #############################################################################\n",
    "# Classification and ROC analysis\n",
    "\n",
    "# Run classifier with cross-validation and plot ROC curves\n",
    "cv = StratifiedKFold(n_splits=6)\n",
    "classifier = svm.SVC(kernel='linear', probability=True,\n",
    "                     random_state=random_state)\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "    classifier.fit(X[train], y[train])\n",
    "    viz = plot_roc_curve(classifier, X[test], y[test],\n",
    "                         name='ROC fold {}'.format(i),\n",
    "                         alpha=0.3, lw=1, ax=ax)\n",
    "    interp_tpr = interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='blue',\n",
    "        label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='green',\n",
    "        label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "       title=\"Receiver operating characteristic for {}\".format(classifier.__class__.__name__))\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from goatools.godag.go_tasks import get_go2parents\n",
    "\n",
    "GO_ID = 'GO:0008150'  # regulation of metabolic process - 0019222\n",
    "optional_relationships = set()\n",
    "go2parents_isa = get_go2parents(godag, optional_relationships)\n",
    "print(go2parents_isa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppp():\n",
    "    print(godag['GO:0008150'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_gosubdag = GoSubDag('GO:0048522', godag, relationships=False, prt=False)\n",
    "tmp_gosubdag.rcntobj.go2parents['GO:0048522']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_godag_isa():\n",
    "        #Now build the hierarchy, meaning each node is represented by the no. of all its descendants\n",
    "    genes2terms = pd.DataFrame()\n",
    "    gene2terms = {}\n",
    "    for index, row in gene2sl.iterrows():\n",
    "        for gene in row['genes'].split(\"$\"):\n",
    "            #No such gene, build it\n",
    "            if gene not in gene2terms:\n",
    "                go_ids = gene2goid.get(gene)\n",
    "                if go_ids is None:\n",
    "                    print(\"Could not find the gene {} in GAF\".format(gene))               \n",
    "                else:\n",
    "                    gene2terms[gene] = {}\n",
    "                    for go_id in go_ids:\n",
    "                        #go_id = 'GO:0048522'\n",
    "                        term = godag.get(go_id)\n",
    "                        if term.namespace == 'biological_process':\n",
    "                            # Create a subset of the GO DAG which contains:\n",
    "                            # The selected GO term and the 'is_a' GO terms above it, by setting relationships=False\n",
    "                            gosubdag = GoSubDag(go_id, godag, relationships=False, prt=False) \n",
    "                            ancestors = defaultdict(set)\n",
    "                            if go_id in gosubdag.rcntobj.go2parents:\n",
    "                                for p_go in gosubdag.rcntobj.go2parents[go_id]:\n",
    "                                    dict_anc = gosubdag.go2nt[p_go]._asdict()\n",
    "                                    ancestors[dict_anc['depth']].add(dict_anc['GO'])\n",
    "                            #print(ancestors)       \n",
    "                            #Get the leaf GO term\n",
    "                            if go_id not in gene2terms[gene]:\n",
    "                                gene2terms[gene][go_id] = 1\n",
    "                            else:\n",
    "                                gene2terms[gene][go_id] += 1\n",
    "                            #Sum up all the ancestors values\n",
    "                            count_genes = 1  \n",
    "                            for level in range(len(ancestors) - 1, -1, -1):\n",
    "                                for GO in ancestors[level]:\n",
    "                                    if GO not in gene2terms[gene]:\n",
    "                                        gene2terms[gene][GO] = count_genes\n",
    "                                    else:\n",
    "                                        gene2terms[gene][GO] += count_genes                                \n",
    "                                count_genes += len(ancestors[level])  \n",
    "\n",
    "        #Build the combination of the 2 genes\n",
    "        g1, g2 = row['genes'].split(\"$\")\n",
    "        gene1 = gene2terms[g1]\n",
    "        gene2 = gene2terms[g2]             \n",
    "        genesdict = {key: gene1.get(key, 0) + gene2.get(key, 0)\n",
    "                     for key in set(gene1) | set(gene2)}\n",
    "        #print(genesdict)\n",
    "        genesdict['genes'] = row['genes']\n",
    "        genesdict['sl'] = row['sl']\n",
    "        #Add the final line and clean NaN\n",
    "        genes2terms = genes2terms.append(genesdict, ignore_index=True)\n",
    "        genes2terms = genes2terms.fillna(0)\n",
    "        #print(genes2terms)\n",
    "        #break\n",
    "        if index == 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun build_godag_isa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes2terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "outfile = 'mnmc_lite.features.npz'\n",
    "npzfile = np.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile['features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile['overlay_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df22  = pd.DataFrame()\n",
    "ll = []\n",
    "ll.append({'GO:001':1, 'GO:004':4})\n",
    "ll.append({'GO:003':3, 'GO:005':5})\n",
    "df22 = df22.append(ll, ignore_index=True)\n",
    "df22 = df22.fillna(0)\n",
    "df22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# df = pd.DataFrame([{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}])\n",
    "# for index, row in df.iterrows():\n",
    "#     print(str(index) + '\\n')\n",
    "#     print(row['c1'], row['c2'])\n",
    "# df = pd.DataFrame(columns=['lib', 'qty1', 'qty2', 'qty3', 'qty4'])\n",
    "# df2 = pd.DataFrame(columns=['lib', 'qty1', 'qty2'])\n",
    "# for i in range(5):\n",
    "#     df2.loc[i] = ['name' + str(i)] + list(randint(10, size=2))\n",
    "# df3 = pd.DataFrame(columns=['lib', 'qty1', 'qty2'])\n",
    "# for i in range(5):\n",
    "#     df3.loc[i] = ['name' + str(i)] + list(randint(10, size=2))\n",
    "# df.loc[0] = df2[df2.lib == 'name0'] + df3[df3.lib == 'name0'] \n",
    "# df\n",
    "# df2\n",
    "# df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Tuples\n",
    "students = [ ('jack', 34, 'Sydeny' , 'Australia') ,\n",
    "             ('Riti', 30, 'Delhi' , 'India' ) ,\n",
    "             ('Vikas', 31, 'Mumbai' , 'India' ) ,\n",
    "             ('Neelu', 32, 'Bangalore' , 'India' ) ,\n",
    "             ('John', 16, 'New York' , 'US') ,\n",
    "             ('Mike', 17, 'las vegas' , 'US')  ]\n",
    "#print('{NS} {GO} D{depth:02} {GO_name}'.format(**gosubdag.go2nt[p_go]._asdict()))\n",
    "#Create a DataFrame object\n",
    "dfObj = pd.DataFrame(students, columns = ['Name' , 'Age', 'City' , 'Country'], index=['a', 'b', 'c' , 'd' , 'e' , 'f'])\n",
    "# Pass the row elements as key value pairs to append() function \n",
    "dfObj = dfObj.append({'Name' : 'Sahil' , 'City' : 'my butt'} , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty = defaultdict(set)\n",
    "ty['YW2'] = {'go0001':1, 'go0002':3}\n",
    "'YW2' not in ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {'a': 5, 'b': 7}\n",
    "dict2 = {'a': 3, 'c': 1}\n",
    "\n",
    "result = {key: dict1.get(key, 0) + dict2.get(key, 0)\n",
    "          for key in set(dict1) | set(dict2)}\n",
    "result['genes'] = 'YSYD$YSHS2'\n",
    "result['sl'] = 0\n",
    "ff = pd.DataFrame()\n",
    "ff = ff.append(result, ignore_index=True)\n",
    "ff = ff.append({}, ignore_index=True)\n",
    "ff = ff.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "genes2terms = pd.DataFrame()\n",
    "genes2terms = pd.read_pickle(\"genes2terms.pkl\")\n",
    "genes2terms = genes2terms.set_index('genes')\n",
    "#Get the standard model to which we are comparing\n",
    "standard_model = pd.read_csv('all.onto_genes.features.cv_all.rf.predictions', header=None, names=[\"prob\"])\n",
    "standard_model['sl'] = -1\n",
    "standard_model.loc[standard_model['prob'] >= 0.5,'sl'] = 1\n",
    "standard_model.loc[standard_model['prob'] < 0.5,'sl'] = 0\n",
    "standard_model['pairs'] = genes2terms.index.values\n",
    "standard_model = standard_model.set_index('pairs')\n",
    "standard_model = standard_model.head(5000)\n",
    "# Set the X, y data\n",
    "X = genes2terms.drop(['sl'], axis=1)\n",
    "y = genes2terms['sl']\n",
    "X = X.head(5000)\n",
    "y = y.head(5000)\n",
    "# Run classifier with cross-validation  \n",
    "cv = StratifiedKFold(n_splits=6)\n",
    "classifier = LogisticRegression(solver='lbfgs', max_iter=50)\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "    #Fit the model\n",
    "    classifier.fit(X.iloc[train], y.iloc[train])\n",
    "    #Get the predictions and keep AUC values for later plot\n",
    "    viz = plot_roc_curve(classifier, X.iloc[test], y.iloc[test],\n",
    "                         name='ROC fold {}'.format(i),\n",
    "                         alpha=0.3, lw=1, ax=ax)\n",
    "    interp_tpr = interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "# Plot ROC curves        \n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='blue',\n",
    "        label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='green',\n",
    "        label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                label=r'$\\pm$ 1 std. dev.')\n",
    "#Now the standard model\n",
    "standard_auc = roc_auc_score(y, standard_model['prob'])\n",
    "#print('Standard: ROC AUC=%.3f' % (standard_auc))\n",
    "base_fpr, base_tpr, _ = roc_curve(y, standard_model['prob'])\n",
    "ax.plot(base_fpr, base_tpr, label=r'Standard ROC (AUC=%.3f)' % (standard_auc), color='red')\n",
    "#Design of plot\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "       title=\"Logistic ROC compared to standard model\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
